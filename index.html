
<!DOCTYPE html>
<html>
    <head>
        <title>Qiuqiang Kong's Homepage</title>
        <link rel="stylesheet" href="assets/css/stylesheet.css" />
        <script src="https://use.fontawesome.com/3ecad3c41f.js"></script>
    </head>
    <body>

        <div class="col-3 nav">
    <a href="#"><img src="assets/images/profile.jpg" class="w3-round" width="60%" /></a>
    <h1>Qiuqiang Kong</h1>
    <p>University of Surrey</p>
    <p>q.kong [at] surrey.ac.uk </p>
</div>

        <div class="col-9 col-offset-3">
            
            <!-- biography -->
            <div class="bio">
    <h1> About me</h1>
    <p>I am a final year Ph. D. student at Centre for Vision, Speech and Signal processing (CVSSP), University of Surrey under the superviosion of Profesor <a href="https://www.surrey.ac.uk/people/mark-plumbley">Mark. D. Plumbley</a>. My research interests include sound understanding and audio processing with artificial intelligence. My research topics include audio tagging, sound event detection, source separation of real-world sounds, general audio processing and music signal processing. I obtained my bachelor and master degree at South China University of Technology in 2012 and 2015. My <a href="assets/cv_kqq.pdf" target="_blank">CV</a> can be downloaded and <a href="https://scholar.google.com/citations?user=B6O3SycAAAAJ&hl=en&oi=ao">Google scholar</a> can be viewed.</p>

    <p><b>Contact:</b> q.kong [at] surrey.ac.uk</p>

<!-- publications -->
<div class="paper-list">
    <h1>Selected Publications</h1>
    <ul>
        
      <li><div class="paper">
        <b>Cross-task learning for audio tagging, sound event detection and spatial localization: DCASE 2019 baseline systems</b>&nbsp<a class="paper-link" href="https://arxiv.org/pdf/1904.03476" target="_blank">[pdf]</a>
        <a class="paper-code" href="https://github.com/qiuqiangkong/dcase2019_task1" target="_blank">[code]</a> <br />
        <span class="paper-author"><b>Qiuqiang Kong</b>, Yin Cao, Turab Iqbal, Yong Xu, Wenwu Wang, Mark D. Plumbley</span> <br />
        <span class="paper-conf"><b>arXiv preprint arXiv:1904.03476, 2019</b>
        <br />
        </div>
      </li>

      <li><div class="paper">
        <b>Weakly labelled audioset tagging with attention neural networks</b>&nbsp<a class="paper-link" href="https://epubs.surrey.ac.uk/852511/1/KongYuXuIWP19-aslp-audioset_accepted_ieee.pdf" target="_blank">[pdf]</a>
        <a class="paper-code" href="https://github.com/qiuqiangkong/audioset_classification" target="_blank">[code]</a> <br />
        <span class="paper-author"><b>Qiuqiang Kong</b>, Changsong Yu, Yong Xu, Turab Iqbal, Wenwu Wang, Mark D. Plumbley</span> <br />
        <span class="paper-conf"> <b>IEEE/ACM Transactions on Audio, Speech, and Language Processing, 2019 </b>
        <br />
        </div>
      </li>

      <li><div class="paper">
        <b>Single-Channel Signal Separation and Deconvolution with Generative Adversarial Networks</b>&nbsp<a class="paper-link" href="https://arxiv.org/pdf/1906.07552" target="_blank">[pdf]</a>
        <a class="paper-code" href="https://github.com/qiuqiangkong/gan_separation_deconvolution" target="_blank">[code]</a> <br />
        <span class="paper-author"><b>Kong, Qiuqiang</b>, Yong Xu, Wenwu Wang, Philip J. B. Jackson, Mark D. Plumbley</span> <br/>
        <span class="paper-conf"><b>IJCAI 2019</b>
        <br />
        </div>
      </li>

      <li><div class="paper">
        <b>Polyphonic Sound Event Detection and Localization using a Two-Stage Strategy</b>&nbsp<a class="paper-link" href="https://arxiv.org/pdf/1905.00268" target="_blank">[pdf]</a>
        <a class="paper-code" href="https://github.com/yinkalario/Two-Stage-Polyphonic-Sound-Event-Detection-and-Localization" target="_blank">[code]</a>&nbsp<span style="font-weight:bold;color:red">Best reproducible award</span> <br />
        <span class="paper-author">Yin Cao*, <b>Qiuqiang Kong*</b>, Turab Iqbal, Fengyan An, Wenwu Wang, Mark D. Plumbley</span> <br />
        <span class="paper-conf"><b>DCASE Workshop 2019</b>
        <br />
        </div>
      </li>

      <li><div class="paper">
        <b>Divergence Based Weighting for Information Channels in Deep Convolutional Neural Networks for Bird Audio Detection</b>&nbsp<a class="paper-link" href="http://150.162.46.34:8080/icassp2019/ICASSP2019/pdfs/0003052.pdf" target="_blank">[pdf]</a><br/>
        <span class="paper-author">Cemre Zor, Muhammad Awais, Josef Kittler, Miroslaw Bober, Sameed Husain, <b>Qiuqiang Kong</b>, Christian Kroos</span> <br />
        <span class="paper-conf"><b>ICASSP 2019</b>
        <br />
        </div>
      </li>

      <li><div class="paper">
        <b>Acoustic Scene Generation with Conditional Samplernn</b>&nbsp<a class="paper-link" href="http://epubs.surrey.ac.uk/850808/1/Acoustic%20scene%20generation%20with%20conditional%20SampleRNN.pdf" target="_blank">[pdf]</a>
        <a class="paper-code" href="https://github.com/qiuqiangkong/sampleRNN_acoustic_scene_generation" target="_blank">[code]</a> <br />
        <span class="paper-author"><b>Qiuqiang Kong</b>, Yong Xu, Turab Iqbal, Yin Cao, Wenwu Wang, Mark D. Plumbley</span><br />
        <span class="paper-conf"><b>ICASSP 2019</b>
        <br />
        </div>
      </li>

      <li><div class="paper">
        <b>Attention-based Atrous Convolutional Neural Networks: Visualisation and Understanding Perspectives of Acoustic Scenes</b>&nbsp<a class="paper-link" href="http://epubs.surrey.ac.uk/850587/1/RenKongHanPS19-icassp.pdf" target="_blank">[pdf]</a>
        <br />
        <span class="paper-author">Zhao Ren, <b>Qiuqiang Kong</b>, Jing Han, Mark D. Plumbley, Björn W. Schuller</span> <br />
        <span class="paper-conf"><b>ICASSP 2019</b>
        <br />
        </div>
      </li>

      <li><div class="paper">
        <b>Sound Event Detection with Sequentially Labelled Data Based on Connectionist Temporal Classification and Unsupervised Clustering</b>&nbsp<a class="paper-link" href="https://arxiv.org/pdf/1904.12102" target="_blank">[pdf]</a>
        <a class="paper-code" href="" target="_blank">[code]</a> <br />
        <span class="paper-author">Yuanbo Hou, <b>Qiuqiang Kong</b>, Shengchen Li, and Mark D. Plumbley</span> <br />
        <span class="paper-conf"><b>ICASSP 2019</b>
        <br />
        </div>
      </li>

      <li><div class="paper">
        <b>Sound Event Detection and Time–Frequency Segmentation from Weakly Labelled Data</b>&nbsp<a class="paper-link" href="https://arxiv.org/pdf/1804.04715" target="_blank">[pdf]</a>
        <a class="paper-code" href="https://github.com/qiuqiangkong/sed_time_freq_segmentation" target="_blank">[code]</a> <br />
        <span class="paper-author"><b>Qiuqiang Kong</b>, Yong Xu, Iwona Sobieraj, Wenwu Wang, Mark D. Plumbley</span> <br />
        <span class="paper-conf"><b>IEEE/ACM Transactions on Audio, Speech and Language Processing (TASLP), 2019</b>
        <br />
        </div>
      </li>

      <li><div class="paper">
        <b>Capsule routing for sound event detection</b>&nbsp<a class="paper-link" href="https://arxiv.org/pdf/1806.04699" target="_blank">[pdf]</a>
        <a class="paper-code" href="https://github.com/tqbl/gccaps" target="_blank">[code]</a> <br />
        <span class="paper-author">Turab Iqbal, Yong Xu, <b>Qiuqiang Kong</b>, Wenwu Wang</span> <br />
        <span class="paper-conf"><b>EUSIPCO 2018</b>
        <br />
        </div>
      </li>

      <li><div class="paper">
        <b>DCASE 2018 Challenge baseline with convolutional neural networks</b>&nbsp<a class="paper-link" href="https://arxiv.org/pdf/1808.00773" target="_blank">[pdf]</a>
        <a class="paper-code" href="https://github.com/qiuqiangkong/dcase2018_task1" target="_blank">[code]</a> <br />
        <span class="paper-author"><b>Qiuqiang Kong</b>, Turab Iqbal, Yong Xu, Wenwu Wang, Mark D. Plumbley</span> <br />
        <span class="paper-conf"><b>DCASE Workshop 2018</b>
        <br />
        </div>
      </li>

      <li><div class="paper">
        <b>Multi-level attention model for weakly supervised audio classification</b>&nbsp<a class="paper-link" href="https://arxiv.org/pdf/1803.02353" target="_blank">[pdf]</a>
        <a class="paper-code" href="https://github.com/ChangsongYu/Eusipco2018_Google_AudioSet" target="_blank">[code]</a> <br />
        <span class="paper-author">Changsong Yu, Karim Said Barsim, <b>Qiuqiang Kong</b>, Bin Yang</span> <br />
        <span class="paper-conf"><b>DCASE Workshop 2018</b>
        <br />
        </div>
      </li>

      <li><div class="paper">
        <b>A joint separation-classification model for sound event detection of weakly labelled data</b>&nbsp<a class="paper-link" href="https://arxiv.org/pdf/1711.03037" target="_blank">[pdf]</a>
        <a class="paper-code" href="https://github.com/qiuqiangkong/ICASSP2018_joint_separation_classification" target="_blank">[code]</a> <br />
        <span class="paper-author"><b>Qiuqiang Kong</b>, Yong Xu, Wenwu Wang, Mark D. Plumbley</span> <br />
        <span class="paper-conf"><b>ICASSP 2018</b>
        <br />
        </div>
      </li>

      <li><div class="paper">
        <b>Audio set classification with attention model: A probabilistic perspective</b>&nbsp<a class="paper-link" href="https://arxiv.org/pdf/1711.00927" target="_blank">[pdf]</a>
        <a class="paper-code" href="https://github.com/qiuqiangkong/audioset_classification" target="_blank">[code]</a> <br />
        <span class="paper-author"><b>Qiuqiang Kong</b>, Yong Xu, Wenwu Wang, and Mark D. Plumbley</span> <br />
        <span class="paper-conf"><b>ICASSP 2018</b>
        <br />
        </div>
      </li>

      <li><div class="paper">
        <b>Large-scale weakly supervised audio classification using gated convolutional neural network</b>&nbsp<a class="paper-link" href="https://arxiv.org/pdf/1710.00343" target="_blank">[pdf]</a>
        <a class="paper-code" href="https://github.com/yongxuUSTC/dcase2017_task4_cvssp" target="_blank">[code]</a> <br />
        <span class="paper-author">Xu, Yong*, <b>Qiuqiang Kong</b>*, Wenwu Wang, and Mark D. Plumbley</span> <br />
        <span class="paper-conf"><b>ICASSP 2018</b>
        <br />
        </div>
      </li>

      <li><div class="paper">
        <b>Convolutional gated recurrent neural network incorporating spatial features for audio tagging</b>&nbsp<a class="paper-link" href="https://arxiv.org/pdf/1702.07787" target="_blank">[pdf]</a>
        <br />
        <span class="paper-author">Yong Xu, <b>Qiuqiang Kong</b>, Qiang Huang, Wenwu Wang, Mark D. Plumbley</span> <br />
        <span class="paper-conf"><b>IJCNN 2017</b>
        <br />
        </div>
      </li>

      <li><div class="paper">
        <b>Attention and localization based on a deep convolutional recurrent model for weakly supervised audio tagging</b>&nbsp<a class="paper-link" href="https://arxiv.org/pdf/1703.06052.pdf" target="_blank">[pdf]</a>
        <a class="paper-code" href="https://github.com/yongxuUSTC/att_loc_cgrnn" target="_blank">[code]</a><br />
        <span class="paper-author">Yong Xu, <b>Qiuqiang Kong</b>, Qiang Huang, Wenwu Wang, and Mark D. Plumbley</span> <br />
        <span class="paper-conf"><b>INTERSPEECH 2017</b>
        <br />
        </div>
      </li>

      <li><div class="paper">
        <b>A joint detection-classification model for audio tagging of weakly labelled data</b>&nbsp<a class="paper-link" href="https://arxiv.org/pdf/1610.01797" target="_blank">[pdf]</a>
        <a class="paper-code" href="https://github.com/qiuqiangkong/audio_tagging_jdc" target="_blank">[code]</a> <br />
        <span class="paper-author"><b>Qiuqiang Kong</b>, Yong Xu, Wenwu Wang, Mark D. Plumbley</span> <br />
        <span class="paper-conf"><b>ICASSP 2017</b>
        <br />
        </div>
      </li>

      <li><div class="paper">
        <b>Deep neural network baseline for DCASE challenge 2016</b>&nbsp<a class="paper-link" href="http://epubs.surrey.ac.uk/813518/1/Deep%20Neural%20Network%20Baseline%20for%20DCASE%20Challenge%202016%20Qiuqiang%20Kong%20v0%205.pdf" target="_blank">[pdf]</a>
        <a class="paper-code" href="https://github.com/qiuqiangkong/DCASE2016_Task1" target="_blank">[code]</a> <br />
        <span class="paper-author"><b>Qiuqiang Kong</b>, Iwona Sobieraj, Wenwu Wang, Mark Plumbley</span> <br />
        <span class="paper-conf"><b>DCASE Workshop 2016</b>
        <br />
        </div>
      </li>
    </ul>
    </div>

            <!-- awards -->
    <div class="award">
    <h1>Patents</h1>
    <ul>
        <li>Large scale music fingerprint and retrieval (CN103853836), bought by KUGOU, 2014.</li>
    </ul>
    </div>

    <div id="footer">
        <span class="footer">
          Profile photo took in Calgary, Canada in 2018 <br>
          This homepage is adapted from <a href="https://shichenliu.github.io/" target="_blank">Shichen Liu</a>'s homepage.
        </span>
    </div>

        <script src="/assets/js/tool.js"></script>
    </body>
</html>