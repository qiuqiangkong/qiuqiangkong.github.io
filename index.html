<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<div id="container" style="height=2000px; width: 1500px; float: center;">
<div id="menu" style="background-color: #00467f; height: 2000px; width: 200px; float: left;">
<h2><a href="http://www.rochester.edu/"><img src="resource/rochester-logo.png" /></a></h2>
<h2 class="menu">Home</h2>
<h2 class="menu">CV</h2>
<h2 class="menu">Research</h2>
<h2 class="menu">Publications</h2>
<h2 class="menu">Teaching</h2>
<h2 class="menu">Links</h2>
<!--        <a href="resource/Research.html", style="text-decoration:none"><h2 class="menu">Research</h2></a>
        <a href="resource/Publications.html", style="text-decoration:none"><h2 class="menu">Publications</h2></a>
        <a href="resource/Resources.html", style="text-decoration:none"><h2 class="menu">Resources</h2></a>
        <a href="http://www.ece.rochester.edu/projects/air/index.html", style="text-decoration:none"><h2 class="menu">AIR Lab</h2></a>--></div>
<div id="content" style="background-color: #eeeeee; height: 2000px; width: 900px; float: left;">
<div id="infopic" style="background-color: #eeeeee; height: 350px; width: 300px; float: left;">
<h2><img src="resource/qiuqiangkong2018.jpg" /></h2>
</div>
<div id="info" style="background-color: #eeeeee; height: 350px; width: 600px; float: left;">
<h2 class="alignleft">Qiuqiang Kong (孔秋强)</h2>
<p>PhD Student<br /> Centre for Vision, Speech and Signal Processing (CVSSP)<br /> University of Surrey <br /> <a href="https://scholar.google.co.uk/citations?user=B6O3SycAAAAJ&amp;hl=en&amp;oi=ao">Google Scholar Profile</a><br /> Email: q.kong@surrey.ac.uk</p>
</div>
<div id="separator" style="background-color: #eeeeee; width: 900px; float: left;"><img src="resource/space.png" width="450" height="2" /></div>
<div class="padded" style="background-color: #eeeeee; width: 850px; float: left;">
<h3>Research interests</h3>
My research concerns audio and music processing with AI: using machine learning and signal processing for analysis, recognition and generation of sounds. My focus is on detection, classification and separation of acoustic scenes and events, particularly real-world sounds, using methods such as deep learning and generative models. My research target is to make a computer to understand audio as humans do.
<h3>News &amp; Events</h3>
<strong>01/08/2018:</strong> Ranked the 3rd (out of 558 teams) in the DCASE 2018 Task 2 General-purpose audio tagging of Freesound challenge in the private leaderboard of Kaggle challenge (with Turab Iqbal). <br /><br /> <strong>02-06/08/2018: </strong> Presenting the music source separation system in LVA-ICA conference (With Dominic Ward). <br /><br /> <strong>24/05/2018: </strong> Giving a talk of deep learning in AES 2018 conference, Milan, Italy. <br /><br /> <strong>16-20/04/2018: </strong> Presenting 3 accepted ICASSP paper in Calgary, Canada. <br /><br />
<h3>Brief bio</h3>
Currently I am a PhD student of Centre of Vision, Speech and Signal Processing (CVSSP), University of Surrey, supervised by professor Mark D. Plumbley. I receieved my master and bachelor's degrees from South China University of Technology (SCUT) in 2015 and 2012, respectively. I interned in Audio Analytic Ltd. in 2017.</div>
</div>
</div>
<div id="container" style="width: 1100px; float: center;">
<p class="aligncenter">Updated on <!-- #BeginDate format:Am1 -->August 22, 2018<!-- #EndDate --></p>
</div>
