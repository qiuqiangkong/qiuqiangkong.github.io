<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<div id="container" style="height=2000px; width: 1500px; float: center;">
<div id="menu" style="background-color: #00467f; height: 2000px; width: 200px; float: left;">
<h2><a href="http://www.rochester.edu/"><img src="resource/rochester-logo.png" /></a></h2>
<h2 class="menu">Home</h2>
<h2 class="menu">CV</h2>
<h2 class="menu">Research</h2>
<h2 class="menu">Publications</h2>
<h2 class="menu">Teaching</h2>
<h2 class="menu">Links</h2>
<!--        <a href="resource/Research.html", style="text-decoration:none"><h2 class="menu">Research</h2></a>
        <a href="resource/Publications.html", style="text-decoration:none"><h2 class="menu">Publications</h2></a>
        <a href="resource/Resources.html", style="text-decoration:none"><h2 class="menu">Resources</h2></a>
        <a href="http://www.ece.rochester.edu/projects/air/index.html", style="text-decoration:none"><h2 class="menu">AIR Lab</h2></a>--></div>
<div id="content" style="background-color: #eeeeee; height: 2000px; width: 900px; float: left;">
<div id="infopic" style="background-color: #eeeeee; height: 350px; width: 300px; float: left;">
<h2><img src="resource/qiuqiangkong2018.jpg" /></h2>
</div>
<div id="info" style="background-color: #eeeeee; height: 350px; width: 600px; float: left;">
<h2 class="alignleft">Qiuqiang Kong (孔秋强)</h2>
<p>PhD Student<br /> Centre for Vision, Speech and Signal Processing (CVSSP)<br /> University of Surrey <br /> <a href="https://scholar.google.co.uk/citations?user=B6O3SycAAAAJ&amp;hl=en&amp;oi=ao">Google Scholar Profile</a><br /> Email: q.kong@surrey.ac.uk</p>
</div>
<div id="separator" style="background-color: #eeeeee; width: 900px; float: left;"><img src="resource/space.png" width="450" height="2" /></div>
<div class="padded" style="background-color: #eeeeee; width: 850px; float: left;">
<h3>News &amp; Events</h3>
<ul>
<li>01/08/2018: Ranked the 3rd (out of 558 teams) in the DCASE 2018 Task 2 General-purpose audio tagging of Freesound in the private leaderboard of Kaggle challenge (with Turab Iqbal). </li>
<li>02-06/08/2018: Our group organized the LVA-ICA conference in University of Surrey. </li> 
  
</ul>
<h3><span style="color: red;">News</span></h3>
<ul>
<li>08/2018 - Our University of Rochester Multi-Modal Music Performance (URMP) dataset is finally online. Check <a href="http://www.ece.rochester.edu/projects/air/projects/URMP.html">this</a> out!</li>
<li>06/2018 - Two papers were accepted to ISMIR 2018, one on visual performance generation and the other on music harmonization. Congrats, Bochen and Yujia!</li>
<li>02/2018 - Five papers were accepted to ICASSP 2018. Congrats Yichi, Bochen, Ray, Emre, and Zhihan!</li>
<li>12/2017 - Andrea passed his PhD defense. Congratulations, Dr. Cogliati, my first PhD student!!</li>
<li>10/2017 - Our ISMIR paper won one of the <strong>best paper award nominations</strong>. Congratulations, Bochen!</li>
<li>08/2017 - I received an NSF BIGDATA grant to develop audio-visual scene understanding algorithms with Chenliang Xu from CS. Thanks for your generous support, NSF!</li>
<li>07/2017 - I received a University of Rochester AR/VR Pilot Grant to develop a synthetic talking face to assist hearing-impaired along with Ross Maddox from BME and Chenliang Xu from CS. Thanks for your generous support, UR!</li>
<li>07/2017 - I received a University of Rochester AR/VR Pilot Grant to develop spatial audio techniques for live streaming, with Ming-Lun Lee from ECE and Matthew Brown from Eastman. Thanks for your generous support, UR!</li>
<li>07/2017 - Our SMC paper won one of the <strong>best paper awards</strong>. Congratulations, Bochen!</li>
<li>06/2017 - Two papers were accepted by WASPAA 2017.</li>
<li>06/2017 - Two papers were accepted by ISMIR 2017.</li>
<li>06/2017 - Andrea, Yichi and Zhiyao attended <a href="http://music.cs.northwestern.edu/mmad/">MMAD</a> and gave presentations.</li>
<li>05/2017 - I gave talks at USTC, SUSTC, PKU-Shenzhen, SJTU, and Fudan University in China.</li>
<li>04/2017 - One paper was accepted by SMC 2017.</li>
<li>02/2017 - We hosted <a href="http://nemisig.wixsite.com/2017">NEMISIG 2017 + HAMR</a> at the University of Rochester!</li>
<li>02/2017 - Our lab received a GPU donation from NVIDIA. Thanks for your generous support, NVIDIA!</li>
<li>12/2016 - Three papers were accepted by ICASSP 2017.</li>
<li>12/2016 - I gave a talk on "Complete Music Transcription" at the Music Signal Processing session at the 5th joint meeting between the Acoustical Society of America and the Acoustical Society of Japan.</li>
<li>11/2016 - I gave a talk on "Complete Music Transcription" at the WNYISPW 2016 workshop.</li>
<li>11/2016 - I gave a talk on "The Machine Musicianship" at Beihang University.</li>
<li>11/2016 - I gave a talk on "AIR Lab Research Overview" at the Chinese Sound and Music Technology (CSMT) workshop.</li>
<li>09/2016 - I gave a talk on "Sound Interactions" at Indiana University Bloomington.</li>
<li>08/2016 - I gave a talk on "Sound Retrieval through Vocal Imitation" at the <a href="http://sungyoungk.wixsite.com/ialab/riaes">RIASE workshop</a>.</li>
<li>08/2016 - I received an NSF grant to develop <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1617107">Algorithms for Query by Example of Audio Databases</a> with Bryan Pardo from Northwestern University! Thanks for your generous support, NSF!</li>
<li>08/2016 - I received a University of Rochester Goergen Institute for Data Science Collaborative Pilot Award Program in Health Analytics to work on ECG Signal Analysis with Mina Attin from School of Nursing! Thanks for your generous support, UR!</li>
</ul>
<!--            <p>I gave a tutorial on <strong>Automatic Music Transcription</strong> together with <a href=""http://www.eecs.qmul.ac.uk/~emmanouilb/>Emmanouil Benetos</a> at <a href="ismir2015.uma.es/">ISMIR 2015</a>. Slides and bibliography can be found <a href="http://c4dm.eecs.qmul.ac.uk/ismir15-amt-tutorial/">here</a>.</p>--></div>
<div id="separator" style="background-color: #eeeeee; width: 900px; float: left;"><img src="resource/space.png" width="450" height="2" /></div>
<div class="padded" style="background-color: #eeeeee; width: 850px; float: left;">
<h3>AIR Lab Is Recruiting</h3>
<p>I am looking for strongly motivated PhD students to work with me in the <a href="http://www.ece.rochester.edu/projects/air/index.html">Audio Information Research (AIR) lab</a> on cool computer audition projects. Students are expected to have a solid background in mathematics, programming, and academic writing. Experiences in music activities will be a plus. <strong>Most importantly, students should be fascinated by human's capability in perceiving and understanding sounds, and are willing to make computers to achieve this capability!</strong> If you are interested, please apply through the university's admission website, and mention my name in your personal statement. You are also welcome to send me an email, but I may not have the bandwidth to reply to every email. If you are in the Rochester area, please feel free to stop by my office for a chat.</p>
<p>If you are a master's or undergrad student who wants to do a project/thesis with me, you are welcome too. Please send me an email or stop by my office.</p>
</div>
<div id="separator" style="background-color: #eeeeee; width: 900px; float: left;"><img src="resource/space.png" width="450" height="2" /></div>
<div class="padded" style="background-color: #eeeeee; width: 850px; float: left;">
<h3>Brief Bio</h3>
<p>I am an assistant professor in the <a href="http://www.ece.rochester.edu/">Department of Electrical and Computer Engineering</a> at the <a href="http://www.rochester.edu/">University of Rochester</a> since July 2013. I also hold a secondary appointment in the Department of Computer Science and am affiliated faculty of the Goergen Institute for Data Science.</p>
<p>I received my Ph.D. from the Department of Electrical Engineering and Computer Science at Northwestern University under the supervision of Prof. <a href="http://www.cs.northwestern.edu/%7Epardo">Bryan Pardo</a>. I received my bachelor and master's degrees from the Department of Automation at Tsinghua University in 2004 and 2008, respectively, under the supervision of Prof. <a href="http://www.au.tsinghua.edu.cn/szll/bodao/zhangchangshui/english/index.html">Changshui Zhang</a>.</p>
<p>I was a visiting researcher in the Center for Computer Research in Music and Acoustics (CCRMA) at Stanford University in 2007, and in the Perception and Neurodynamics Laboratory at the Ohio State University in 2013. I interned in the Speech group of Microsoft Research Asia (MSRA) in 2007 and 2008, and in the Advanced Technology Labs of Adobe Systems Inc. in 2011.</p>
</div>
<div id="separator" style="background-color: #eeeeee; width: 900px; float: left;"><img src="resource/space.png" width="450" height="2" /></div>
<div class="padded" style="background-color: #eeeeee; width: 850px; float: left;">
<h3>Research Interests</h3>
<p>My research interests lie primarily in the emerging area of Computer Audition, which is about designing intelligent algorithms and systems that can understand sounds, including music, speech and environmental sounds. This is an interdisciplinary area that draws from many fields including signal processing, machine learning, psychoacoustics, music theory, etc. Specific problems that I have been working on include automatic music transcription, sound source separation, audio-score alignment, music annotation and recommendation, speech enhancement and emotion analysis, sound retrieval, and audio-visual analysis of music performances.</p>
</div>
</div>
</div>
<div id="container" style="width: 1100px; float: center;">
<p class="aligncenter">Updated on <!-- #BeginDate format:Am1 -->August 22, 2018<!-- #EndDate --></p>
</div>
